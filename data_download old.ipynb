{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf30aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0115b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = 'https://danepubliczne.imgw.pl/api/data/meteo/'\n",
    "response = requests.get(uri)\n",
    "if response.status_code == 200:\n",
    "    print(\"Data fetched successfully.\")\n",
    "    print(f\"Response body: {response.text}...\")  # Print first 100 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a74cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = './data/raw'\n",
    "years = range(2010, 2026)\n",
    "samples = range(5, 1001, 5)\n",
    "\n",
    "pro_data = './data/processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cdf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, out_path):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    \n",
    "        with open(out_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "            \n",
    "        print(f\"Plik pomyślnie pobrany i zapisany jako: {out_path}\")\n",
    "        return True\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n❌ Błąd podczas pobierania: {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Wystąpił nieoczekiwany błąd: {e}\")\n",
    "        return False\n",
    "        \n",
    "def handle_zip(zip_path, rm_zip=True):\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            extract_path = os.path.splitext(zip_path)[0]\n",
    "            zip_ref.extractall(extract_path)\n",
    "            print(f\"Pliki zostały rozpakowane do: {extract_path}\")\n",
    "        if rm_zip:\n",
    "            os.remove(zip_path)\n",
    "            print(f\"Plik ZIP został usunięty: {zip_path}\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"❌ Błąd: Plik nie jest prawidłowym archiwum ZIP.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Wystąpił nieoczekiwany błąd podczas rozpakowywania: {e}\")\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a56be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    for y in years:\n",
    "        for s in samples:\n",
    "            url = f\"https://danepubliczne.imgw.pl/data/dane_pomiarowo_obserwacyjne/dane_meteorologiczne/terminowe/synop/{y}/{y}_{s}_s.zip\"\n",
    "            filename = url.split('/')[-1]\n",
    "            out_path = os.path.join(extract_dir, filename)\n",
    "            \n",
    "            if download_file(url, out_path):\n",
    "                handle_zip(out_path, rm_zip=True)\n",
    "                print(f\"Pobrano i rozpakowano dane dla roku {y} z {s} próbkami.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1645e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "paths = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            full_path = os.path.join(root, file)\n",
    "            paths.append(full_path)\n",
    "            \n",
    "print(f\"\\nZnaleziono {len(paths)} plików CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths[0], 'rb') as f:\n",
    "    raw_data = f.read(10000)\n",
    "    \n",
    "result = chardet.detect(raw_data)\n",
    "detected_encoding = result['encoding']\n",
    "print(f\"Detected encoding: {detected_encoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"Kod_stacji\", \"Nazwa_stacji\", \"Rok\", \"Miesiąc\", \"Dzień\", \"Godzina\",\n",
    "    \"Wysokosc_chmur_kod\", \"Status_HPOD\",\n",
    "    \"Wysokosc_podstawy_nizszej_m\", \"Status_HPON\",\n",
    "    \"Wysokosc_podstawy_wyzszej_m\", \"Status_HPOW\",\n",
    "    \"Wysokosc_podstawy_opis\", \"Pomiar_przyrzadem_1_P\",\n",
    "    \"Pomiar_przyrzadem_2_P\", \"Widzialnosc_kod\",\n",
    "    \"Status_WID\", \"Widzialnosc_operatora_m\", \"Status_WIDO\",\n",
    "    \"Widzialnosc_automat_m\", \"Status_WIDA\", \"Zachmurzenie_ogolne_oktanty\",\n",
    "    \"Status_NOG\", \"Kierunek_wiatru_stopnie\", \"Status_KRWR\",\n",
    "    \"Predkosc_wiatru_ms\", \"Status_FWR\", \"Poryw_wiatru_ms\",\n",
    "    \"Status_PORW\", \"Temperatura_powietrza_C\", \"Status_TEMP\",\n",
    "    \"Temperatura_termometru_zwilzonego_C\", \"Status_TTZW\",\n",
    "    \"Wskaznik_wentylacji\", \"Wskaznik_lodu\",\n",
    "    \"Cisnienie_pary_wodnej_hPa\", \"Status_CPW\",\n",
    "    \"Wilgotnosc_wzgledna_proc\", \"Status_WLGW\",\n",
    "    \"Temperatura_punktu_rosy_C\", \"Status_TPTR\",\n",
    "    \"Cisnienie_na_poziomie_stacji_hPa\", \"Status_PPPS\",\n",
    "    \"Cisnienie_na_poziomie_morza_hPa\", \"Status_PPPM\",\n",
    "    \"Charakterystyka_tendencji_kod\", \"Wartosc_tendencji\", \"Status_APP\",\n",
    "    \"Opad_za_6_godzin_mm\", \"Status_WO6G\",\n",
    "    \"Rodzaj_opadu_za_6_godzin_kod\", \"Status_ROPT\",\n",
    "    \"Pogoda_biezaca_kod\", \"Pogoda_ubiegla_kod\", \"Zachmurzenie_niskie_oktanty\",\n",
    "    \"Status_CLCM\", \"Chmury_CL_kod\", \"Status_CHCL\", \"Chmury_CL_tekstem\",\n",
    "    \"Chmury_CM_kod\", \"Status_CHCM\", \"Chmury_CM_tekstem\",\n",
    "    \"Chmury_CH_kod\", \"Status_CHCH\", \"Chmury_CH_tekstem\",\n",
    "    \"Stan_gruntu_kod\", \"Status_SGRN\",\n",
    "    \"Niedosyt_wilgotnosci_hPa\", \"Status_DEFI\",\n",
    "    \"Uslonecznienie\", \"Status_USLN\",\n",
    "    \"Wystapienie_rosy_01\", \"Status_ROSW\",\n",
    "    \"Poryw_maksymalny_ms\", \"Status_PORK\",\n",
    "    \"Godzina_porywu\", \"Minuta_porywu\",\n",
    "    \"Temperatura_gruntu_minus5_C\", \"Status_TG05\",\n",
    "    \"Temperatura_gruntu_minus10_C\", \"Status_TG10\",\n",
    "    \"Temperatura_gruntu_minus20_C\", \"Status_TG20\",\n",
    "    \"Temperatura_gruntu_minus50_C\", \"Status_TG50\",\n",
    "    \"Temperatura_gruntu_minus100_C\", \"Status_TG100\",\n",
    "    \"Temperatura_minimalna_12h_C\", \"Status_TMIN\",\n",
    "    \"Temperatura_maksymalna_12h_C\", \"Status_TMAX\",\n",
    "    \"Temperatura_minimalna_przy_gruncie_12h_C\", \"Status_TGMI\",\n",
    "    \"Rownowaznik_wodny_sniegu_mmcm\", \"Status_RWSN\",\n",
    "    \"Wysokosc_pokrywy_snieznej_cm\", \"Status_PKSN\",\n",
    "    \"Wysokosc_swiezo_spadlego_sniegu_cm\", \"Status_HSS\",\n",
    "    \"Wysokosc_sniegu_na_poletku_cm\", \"Status_GRSN\",\n",
    "    \"Gatunek_sniegu_kod\", \"Uksztaltowanie_pokrywy_kod\",\n",
    "    \"Wysokosc_probki_cm\", \"Status_HPRO\",\n",
    "    \"Zapas_wody_w_sniegu_mm\", \"Status_CIPR\"\n",
    "]\n",
    "dfs = []\n",
    "for path in paths:\n",
    "    try:\n",
    "        df = pd.read_csv(path, encoding=detected_encoding, low_memory=False, names=column_names, header=None, sep=',')\n",
    "        dfs.append(df)\n",
    "        print(f\"Pomyślnie wczytano plik: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Błąd podczas wczytywania pliku {path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e0519",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Nazwa_stacji', 'Wysokosc_podstawy_opis', \n",
    "                     'Chmury_CL_tekstem', 'Chmury_CM_tekstem', 'Chmury_CH_tekstem']\n",
    "\n",
    "for df in dfs:\n",
    "    for col in text_cols:\n",
    "        if col in df.columns:\n",
    "            bytes_data = df[col].astype(str).str.encode('iso-8859-1', errors='replace')\n",
    "            df[col] = (\n",
    "                bytes_data.str.decode('cp1250', errors='replace')\n",
    "                .str.strip()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(dfs[0].head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d539bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacje = [tmp['Nazwa_stacji'].unique() for tmp in dfs]\n",
    "stacje_flat = [item for sublist in stacje for item in sublist]\n",
    "unique_stacje = set(stacje_flat)\n",
    "print(f\"\\nŁączna liczba unikalnych stacji przed filtrowaniem: {len(unique_stacje)}\")\n",
    "stacje_sort = sorted(unique_stacje)\n",
    "print(\"Lista unikalnych stacji (posortowana):\")\n",
    "for stacja in stacje_sort:\n",
    "    print(stacja)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7cbb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    tmp[tmp['Nazwa_stacji'].str.contains('WROCŁAW', na=False)] for tmp in dfs\n",
    "]\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.dropna(subset=['Rok', 'Miesiąc', 'Dzień', 'Godzina'])\n",
    "\n",
    "\n",
    "stacje = df['Nazwa_stacji'].unique()\n",
    "print(f\"Stacje: {stacje}\")\n",
    "print(f\"\\nŁączna liczba rekordów po filtrowaniu: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c398f87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPodgląd danych:\")\n",
    "print(tabulate(df.describe(include='all'), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(df.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Słownik do mapowania polskich nazw na angielskie, wymagane przez Pandas\n",
    "column_map = {\n",
    "    'Rok': 'year', \n",
    "    'Miesiąc': 'month', \n",
    "    'Dzień': 'day', \n",
    "    'Godzina': 'hour'\n",
    "}\n",
    "\n",
    "# 1. Tworzymy kopię DataFrame z tylko wymaganymi kolumnami\n",
    "datetime_df = df[['Rok', 'Miesiąc', 'Dzień', 'Godzina']].copy()\n",
    "\n",
    "# 2. Zmieniamy nazwy kolumn na nazwy oczekiwane przez Pandas\n",
    "datetime_df.rename(columns=column_map, inplace=True)\n",
    "\n",
    "# 3. Wykonujemy konwersję\n",
    "daty = pd.to_datetime(datetime_df)\n",
    "\n",
    "# Kontynuujemy Twój oryginalny kod\n",
    "df['Data'] = daty\n",
    "df.set_index('Data', inplace=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fa0594",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(pro_data, exist_ok=True)\n",
    "df.to_csv(os.path.join(pro_data, 'wroclaw_synop_data.csv'), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
